{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NavierStokeExample.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations\n",
        "## Authors: M. Raissi, P. Perdikaris, G.E. Karniadakis\n",
        "## Team: Abby Schmid, Thomas Allard, Yang Xu\n",
        "\n",
        "Imports and installs\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/thomas-allard/APPM5720/blob/master/NavierStokeExample.ipynb)\n"
      ],
      "metadata": {
        "id": "qTtsAJdmzXDC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "z5NCbWFDT8c2",
        "outputId": "48624a19-f9ae-4cbb-d0ed-d0c4ff2ddc75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------- SCIANN 0.6.5.1 ---------------------- \n",
            "For details, check out our review paper and the documentation at: \n",
            " +  \"https://www.sciencedirect.com/science/article/pii/S0045782520307374\", \n",
            " +  \"https://arxiv.org/abs/2005.08803\", \n",
            " +  \"https://www.sciann.com\". \n",
            "\n",
            " Need support or would like to contribute, please join sciann`s slack group: \n",
            " +  \"https://join.slack.com/t/sciann/shared_invite/zt-ne1f5jlx-k_dY8RGo3ZreDXwz0f~CeA\" \n",
            " \n",
            "TensorFlow Version: 2.5.3 \n",
            "Python Version: 3.7.12 (default, Jan 15 2022, 18:48:18) \n",
            "[GCC 7.5.0] \n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install sciann &> /dev/null\n",
        "!pip install matplotlib &> /dev/null\n",
        "!pip install scipy &> /dev/null\n",
        "#!/usr/bin/env python3\n",
        "\n",
        "\n",
        "## exact value of the parameters: lambda1 = 0.9967, lambda2 = 0.0110\n",
        "import numpy as np \n",
        "import sciann as sn \n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io\n",
        "\n",
        "import os\n",
        "# sns.set_theme()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify parameters and things\n",
        "mode = 'test'   # 'test' to load PINN weights from previously trained model\n",
        "                # 'train' to train a new model\n",
        "\n",
        "trained_file = 'trained-navier-stokes.hdf5'\n",
        "data_file = 'cylinder_nektar_wake.mat'"
      ],
      "metadata": {
        "id": "TwD8f3GPEQRH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "for file in glob.glob(\"*.mat\"):\n",
        "  print('file is called:')\n",
        "  print(file)"
      ],
      "metadata": {
        "id": "YYdi_GhsFghy",
        "outputId": "e276a923-6e43-4056-9e50-a44827dbdedf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file is called:\n",
            "cylinder_nektar_wake.mat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define function for subsampling data\n",
        "def PrepareData(num_data, data_file, random=True):\n",
        "    \n",
        "    # Load data\n",
        "    #data = scipy.io.loadmat('/content/' + data_file)\n",
        "    data = scipy.io.loadmat(data_file)\n",
        "    \n",
        "    U_star = data['U_star'] # N x 2 x T\n",
        "    P_star = data['p_star'] # N x T\n",
        "    t_star = data['t'] # T x 1\n",
        "    X_star = data['X_star'] # N x 2\n",
        "    \n",
        "    N = X_star.shape[0]\n",
        "    T = t_star.shape[0]\n",
        "    \n",
        "    # Rearrange Data \n",
        "    XX = np.tile(X_star[:,0:1], (1,T)) # N x T\n",
        "    YY = np.tile(X_star[:,1:2], (1,T)) # N x T\n",
        "    TT = np.tile(t_star, (1,N)).T # N x T\n",
        "    \n",
        "    UU = U_star[:,0,:] # N x T\n",
        "    VV = U_star[:,1,:] # N x T\n",
        "    PP = P_star # N x T\n",
        "    \n",
        "    # Pick random data.\n",
        "    if random:\n",
        "        idx = np.random.choice(N*T, num_data, replace=False)\n",
        "    else:\n",
        "        idx = np.arange(0, N*T)\n",
        "    \n",
        "    x = XX.flatten()[idx,None] # NT x 1\n",
        "    y = YY.flatten()[idx,None] # NT x 1\n",
        "    t = TT.flatten()[idx,None] # NT x 1\n",
        "    \n",
        "    u = UU.flatten()[idx,None] # NT x 1\n",
        "    v = VV.flatten()[idx,None] # NT x 1\n",
        "    p = PP.flatten()[idx,None] # NT x 1\n",
        " \n",
        "    return (x,y,t,u,v,p)\n"
      ],
      "metadata": {
        "id": "CkpMCaGMy2JU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Subsample data for training\n",
        "x_train, y_train, t_train, u_train, v_train, p_train = PrepareData(5000, data_file, random=True)"
      ],
      "metadata": {
        "id": "9vSsXZPszd-k"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up cost function\n",
        "layers = 8\n",
        "neurons = 20\n",
        "\n",
        "x = sn.Variable(\"x\", dtype='float64')\n",
        "y = sn.Variable(\"y\", dtype='float64')\n",
        "t = sn.Variable(\"t\", dtype='float64')\n",
        "\n",
        "P = sn.Functional(\"P\", [x, y, t], layers*[neurons], 'tanh')\n",
        "Psi = sn.Functional(\"Psi\", [x, y, t], layers*[neurons], 'tanh')\n",
        "\n",
        "lambda1 = sn.Parameter(np.random.rand(), inputs=[x,y,t], name=\"lambda1\")\n",
        "lambda2 = sn.Parameter(np.random.rand(), inputs=[x,y,t], name=\"lambda2\")\n",
        "## true value lamdba1 = \n",
        "\n",
        "u = sn.diff(Psi, y)\n",
        "v = -sn.diff(Psi, x)\n",
        "\n",
        "u_t = sn.diff(u, t)\n",
        "u_x = sn.diff(u, x)\n",
        "u_y = sn.diff(u, y)\n",
        "u_xx = sn.diff(u, x, order=2)\n",
        "u_yy = sn.diff(u, y, order=2)\n",
        "\n",
        "v_t = sn.diff(v, t)\n",
        "v_x = sn.diff(v, x)\n",
        "v_y = sn.diff(v, y)\n",
        "v_xx = sn.diff(v, x, order=2)\n",
        "v_yy = sn.diff(v, y, order=2)\n",
        "\n",
        "p_x = sn.diff(P, x)\n",
        "p_y = sn.diff(P, y)\n",
        "\n",
        "# Define constraints \n",
        "d1 = sn.Data(u)\n",
        "d2 = sn.Data(v)\n",
        "d3 = sn.Data(P)\n",
        "\n",
        "c1 = sn.Tie(-p_x, u_t+lambda1*(u*u_x+v*u_y)-lambda2*(u_xx+u_yy))\n",
        "c2 = sn.Tie(-p_y, v_t+lambda1*(u*v_x+v*v_y)-lambda2*(v_xx+v_yy))\n",
        "c3 = sn.Data(u_x + v_y)\n",
        "\n",
        "c4 = Psi*0.0\n",
        "\n",
        "if mode == 'train':\n",
        "# Define the optimization model (set of inputs and constraints)\n",
        "    model = sn.SciModel(\n",
        "        inputs=[x, y, t],\n",
        "        targets=[d1, d2, d3, c1, c2, c3, c4],\n",
        "        loss_func=\"mse\",\n",
        "        plot_to_file='NS-Model.png'\n",
        "    )\n",
        "\n",
        "    input_data = [x_train, y_train, t_train]\n",
        "\n",
        "    data_d1 = u_train\n",
        "    data_d2 = v_train\n",
        "    data_d3 = p_train\n",
        "    data_c1 = 'zeros'\n",
        "    data_c2 = 'zeros'\n",
        "    data_c3 = 'zeros'\n",
        "    data_c4 = 'zeros'\n",
        "    target_data = [data_d1, data_d2, data_d3, data_c1, data_c2, data_c3, data_c4]\n",
        "\n",
        "    ## hyper parameter define\n",
        "\n",
        "    Epochs= 10000\n",
        "    Batch_size=100\n",
        "    Learning_rate=0.001\n",
        "    Reduce_lr_after=1000\n",
        "\n",
        "    #log the data\n",
        "\n",
        "    log_directory = f'../logs/log_layers{layers}_neurons{neurons}_epochs{Epochs}_batchsize{Batch_size}_learning_rate{Learning_rate}_reduce_lr_after{Reduce_lr_after}'\n",
        "\n",
        "    if not os.path.exists(log_directory):\n",
        "        os.makedirs(log_directory)\n",
        "        print(f'{log_directory} is created!')\n",
        "\n",
        "    ##train PINN\n",
        "\n",
        "    history = model.train(\n",
        "        x_true=input_data,\n",
        "        y_true=target_data,\n",
        "        epochs= Epochs,\n",
        "        batch_size= Batch_size,\n",
        "        shuffle=True,\n",
        "        learning_rate= Learning_rate,\n",
        "        reduce_lr_after= Reduce_lr_after,\n",
        "        stop_loss_value=1e-8,\n",
        "        verbose=1,\n",
        "        log_parameters={'parameters':[lambda1,lambda2],\n",
        "                        'freq':1}\n",
        "    )\n",
        "\n",
        "    ## logs and plots\n",
        "    model.save_weights('trained-navier-stokes.hdf5')\n",
        "    ## print iterated parameters value\n",
        "    print(\"lambda1: {},  lambda2: {}\".format(lambda1.value, lambda2.value))\n",
        "    with open(f'../logs/log_layers{layers}_neurons{neurons}_epochs{Epochs}_batchsize{Batch_size}_learning_rate{Learning_rate}_reduce_lr_after{Reduce_lr_after}/parameters_{layers}_{neurons}.txt', 'w') as f:\n",
        "        f.write(f\"lambda1: {lambda1.value},  lambda2: {lambda2.value}\")\n",
        "    print(\"lambda1: {},  lambda2: {}\".format(lambda1.value, lambda2.value))\n",
        "\n",
        "    ## print loss function value\n",
        "    print(\"loss: {}\".format(history.history['loss']))\n",
        "    with open(f'../logs/log_layers{layers}_neurons{neurons}_epochs{Epochs}_batchsize{Batch_size}_learning_rate{Learning_rate}_reduce_lr_after{Reduce_lr_after}/loss_{layers}_{neurons}.txt', 'w') as f:\n",
        "        f.write(f\"loss: {history.history['loss']}\")\n",
        "    ## plot loss function\n",
        "    plt.figure(f'Train_Loss_{layers}_{neurons}')\n",
        "    plt.semilogy(history.history['loss'])\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel('loss')\n",
        "    plt.savefig(f'../logs/log_layers{layers}_neurons{neurons}_epochs{Epochs}_batchsize{Batch_size}_learning_rate{Learning_rate}_reduce_lr_after{Reduce_lr_after}/loss_{layers}_{neurons}.png')\n",
        "    plt.semilogy(history.history['loss'])\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel('loss')"
      ],
      "metadata": {
        "id": "mDiTFpuUzikv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if mode == 'test':\n",
        "    x_test, y_test, t_test, u_test, test, p_test = PrepareData(5000, data_file, random=True)\n",
        "    test_input_data = [x_test, y_test, t_test]\n",
        "\n",
        "    model = sn.SciModel(\n",
        "        inputs=[x, y, t],\n",
        "        targets=[d1, d2, d3, c1, c2, c3, c4],\n",
        "        loss_func=\"mse\",\n",
        "        load_weights_from='trained-navier-stokes.hdf5'\n",
        "    )\n",
        "    test_result = model.predict(test_input_data, batch_size=None, verbose=0, steps=None)\n",
        "    #n_size = int(np.sqrt(x_test.shape[0]))\n",
        "\n",
        "    #ux_mae = mae(ux_test, test_result[0])\n",
        "    #uy_mae = mae(uy_test, test_result[1])\n",
        "    #print(f'UX mae is: {ux_mae}, UY mae is {uy_mae}')\n",
        "    print(\"lambda1: {},  lambda2: {}\".format(lambda1.value, lambda2.value))\n",
        "    #print(\"lambda1: {},  lambda2: {}\".format(lambda_parameter.value, mu_parameter.value, rho_parameter.value))\n",
        "\n",
        "    #import pdb; pdb.set_trace()\n",
        "\n",
        "    #from scipy.io import savemat\n",
        "\n",
        "    #mdic = {\"ux_pred\": test_result[0].reshape(n_size,n_size),\"uy_pred\": test_result[1].reshape(n_size,n_size),\"label\": \"pinn_result_source_0\"}\n",
        "\n",
        "    #savemat(\"pinn_result_source_0.mat\", mdic)\n",
        "\n",
        "\n",
        "\n",
        "    #plt.figure()\n",
        "    #sns.heatmap(test_result[0].reshape(n_size,n_size))\n",
        "    #plt.figure()\n",
        "    #sns.heatmap(test_result[1].reshape(n_size,n_size))\n",
        "    #plt.show()\n",
        "    # st()\n"
      ],
      "metadata": {
        "id": "czfyut7yKEhH",
        "outputId": "58b977aa-c399-415e-fcea-8946d5d4c4f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2424: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lambda1: [0.99794099],  lambda2: [0.0108588]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What should classmates do with trained PINNs?\n",
        "- Plot pressure distribution at some time\n",
        "- Print lambdas"
      ],
      "metadata": {
        "id": "vN0rs7cI1Nak"
      }
    }
  ]
}